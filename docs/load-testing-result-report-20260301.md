# 부하 테스트 장애 리뷰 보고서

## 문서 정보

| 항목 | 내용 |
|------|------|
| **테스트 일자** | 2026-03-01 |
| **테스트 환경** | Docker Compose (로컬) — Small(0.5 vCPU/512MB) vs Medium(1 vCPU/1GB) |
| **테스트 도구** | k6 |
| **테스트 목적** | 콘서트 예약 서비스 핵심 시나리오의 트래픽 처리 능력 검증 및 적정 배포 스펙 도출 |

---

## 현상

### 타임라인

| 시각 | 이벤트 |
|------|--------|
| 09:00 | 테스트 인프라 기동 (Docker Compose — MySQL, Redis, Kafka, app-small/medium) |
| 09:10 | Scenario 1 (Queue Spike) — Small/Medium 순차 실행 |
| 09:30 | Scenario 2 (Reservation Stress) — Small/Medium 실행. **k6 `http_req_failed` threshold FAIL** 감지 |
| 09:55 | Scenario 3 (Payment Load) — Small/Medium 실행. **k6 `http_req_failed` threshold FAIL** 감지 |
| 10:20 | Scenario 4 (Concert Endurance) — Small/Medium 실행. 전 항목 PASS |
| 10:40 | 원인 분석 완료 — threshold FAIL은 k6 메트릭 집계 방식 기인, 비즈니스 로직 정상 |

### 영향 범위

| 시나리오 | 발생 현상 | 영향 컴포넌트 |
|---------|---------|-------------|
| Scenario 1: Queue Spike | 이상 없음 | 대기열(Queue) API |
| **Scenario 2: Reservation Stress** | `http_req_failed` 49% — k6 threshold FAIL | 예약(Reservation) API, Redis 분산락 |
| **Scenario 3: Payment Load** | `http_req_failed` 44.5% — k6 threshold FAIL | 결제(Payment) API, 포인트 잔액 로직 |
| Scenario 4: Concert Endurance | 이상 없음 | 콘서트 조회 API, Redis 캐시 |

### 고객 영향도 (비즈니스 임팩트)

| 구분 | 내용 |
|------|------|
| **실제 서비스 장애 여부** | **없음** — 애플리케이션 에러율(custom metric) 0%, 응답 시간 전 threshold PASS |
| **예약 실패 경험 가능성** | 좌석 50석 전량 소진 후 추가 예약 시도 시 409 응답 수신 (정상 UX) |
| **결제 실패 경험 가능성** | 이미 결제된 예약 재결제 시도 시 4xx 수신 (중복 결제 차단, 정상 UX) |
| **조회 서비스 영향** | 없음 — Redis 캐시 Hit Rate 100%, 응답 시간 평균 1~3ms 수준 |
| **티켓 오픈 트래픽 대응** | 100 VU 스파이크 환경에서 에러율 0%, P95 27ms(Small) / 4ms(Medium) |

---

## 조치 내용

### 장애 원인

**[원인 1] Scenario 2 `http_req_failed` 49% FAIL**

k6의 `http_req_failed`는 기본적으로 HTTP 4xx/5xx 응답을 모두 실패로 집계한다.
Scenario 2에서는 50석 전량 소진 후 지속적으로 예약 시도가 이어지며 409 Conflict가 대량 발생했고,
이것이 threshold `rate<0.05`를 초과하여 k6 FAIL로 표시됨.
그러나 애플리케이션의 `errors` custom metric은 0%로, **비즈니스 로직 및 분산락은 정상 동작**.

**[원인 2] Scenario 3 `http_req_failed` 44.5% FAIL**

Scenario 3에서는 setup 단계에서 20개 예약을 생성하고, 20 VU가 반복적으로 동일 예약에 결제를 시도한다.
최초 1회 결제 성공(20건) 이후, 이미 CONFIRMED 상태인 예약에 대한 재결제는 4xx로 차단된다.
반복 루프(총 ~90회 iteration) 중 결제 성공은 20건뿐이어서 `http_req_failed`가 44.5%로 집계됨.
`errors` custom metric은 0%로, **결제 중복 방지 로직은 정상 동작**.

**[공통 원인 요약]**

k6 `http_req_failed` threshold가 비즈니스 예외(409, 4xx)를 실패로 간주하도록 설정되어 있어,
정상 비즈니스 동작이 부하 테스트 임계값 위반으로 표시됨.

### 해소 타임라인

| 시각 | 조치 |
|------|------|
| 09:30 | Scenario 2 FAIL 감지 → 로그 및 custom metric(`errors`) 확인 시작 |
| 09:40 | k6 `http_req_failed` 집계 방식 확인 — 4xx 포함 여부 파악 |
| 09:55 | Scenario 3 FAIL 동일 패턴 확인 |
| 10:40 | 원인 분석 완료 — threshold FAIL이 k6 설정 한계에 기인함을 확인 |

### 실제 단기 대응책

1. **결과 해석 기준 보완**: `http_req_failed` FAIL은 k6 집계 방식 특성으로 표시된 것임을 보고서에 명시. 비즈니스 정상 여부는 custom `errors` metric(0%)으로 판단.
2. **재실행 없이 결론 확정**: custom metric 에러율 0%, 응답 시간 threshold 전 PASS 확인으로 서비스 정상성 확인 완료.

### 후속 대응 계획

1. k6 `http_req_failed` threshold를 비즈니스 맥락에 맞게 재설정 (409, 422 등 예상 가능한 응답 코드 제외)
2. Scenario 3 테스트 시나리오를 매 iteration마다 새 예약을 생성하도록 개선 — 반복 결제 시도 패턴 제거
3. 테스트 완료 후 k6 threshold 기준과 비즈니스 에러 정의를 팀 내 정리

---

## 상세 분석

### 5-Whys 분석

#### [이슈 1] Scenario 2: `http_req_failed` threshold FAIL (49%)

| 단계 | Why |
|------|-----|
| **Why 1** | k6 `http_req_failed` threshold가 `rate<0.05`를 초과했다 |
| **Why 2** | 전체 요청 2,500건 중 약 1,200건이 HTTP 실패(4xx)로 집계됐다 |
| **Why 3** | 1,200건이 409 Conflict 응답이었다 |
| **Why 4** | 좌석 50석이 소진된 이후에도 50 VU가 지속적으로 동일 일정에 예약을 시도했다 |
| **Why 5** | k6 threshold가 비즈니스 예외인 409를 일반 HTTP 실패와 동일하게 처리하도록 설정되어 있었다 |

**결론**: 분산락과 예약 충돌 처리 로직은 정상. threshold 설정에 비즈니스 예외 정의가 누락된 것이 원인.

#### [이슈 2] Scenario 3: `http_req_failed` threshold FAIL (44.5%)

| 단계 | Why |
|------|-----|
| **Why 1** | k6 `http_req_failed` threshold가 `rate<0.02`를 초과했다 |
| **Why 2** | 920건 중 약 410건이 HTTP 실패(4xx)로 집계됐다 |
| **Why 3** | 결제 시도 중 성공은 20건뿐이고 나머지는 4xx로 응답받았다 |
| **Why 4** | 이미 CONFIRMED 상태인 예약은 재결제가 차단되어 4xx가 반환됐다 |
| **Why 5** | 테스트 시나리오가 20건 예약에 대해 반복적으로 결제를 시도하는 구조여서, 1회 성공 후 나머지 iteration은 항상 실패한다 |

**결론**: 결제 중복 방지 로직은 정상. 테스트 시나리오 설계가 실제 결제 플로우(예약 1건에 결제 1회)를 반영하지 못한 것이 원인.

---

## 대응 방안

### 액션 아이템

#### Short-term (즉시 ~ 1주일)

| 항목 | 담당 | 설명 |
|------|------|------|
| k6 `http_req_failed` 기준 수정 | 개발팀 | `setResponseCallback`으로 409, 422 등 비즈니스 예외 코드를 성공으로 간주하도록 threshold 재정의 |
| Scenario 3 시나리오 개선 | 개발팀 | 매 iteration마다 새 예약 생성 후 결제 처리 → 반복 결제 시도 패턴 제거 |
| 배포 스펙 결정 | 인프라팀 | Medium(1 vCPU / 1GB) 스펙으로 프로덕션 배포 확정. 인스턴스 2대 이상 구성 |

#### Mid-term (1주일 ~ 1개월)

| 항목 | 담당 | 설명 |
|------|------|------|
| 더 높은 VU 부하 테스트 | 개발팀 | 현재 최대 100 VU → 실 서비스 예상 트래픽(500 VU 이상) 수준으로 재테스트 |
| 지속 부하 시간 연장 | 개발팀 | Scenario 4 Endurance를 30분 이상 실행해 메모리 누수 여부 장기 검증 |
| 모니터링 대시보드 구축 | 인프라팀 | Prometheus + Grafana 기반 실시간 APM 대시보드 운영 환경 구성 |
| 결제 실패율 알림 설정 | 인프라팀 | 실 서비스에서 결제 실패율 > 1% 시 Slack 알림 설정 |

#### Long-term (1개월 이후)

| 항목 | 담당 | 설명 |
|------|------|------|
| 부하 테스트 CI 통합 | 개발팀 | PR 병합 시 Scenario 1 (Queue Spike) 자동 실행 및 threshold 검증 파이프라인 구축 |
| 캐시 전략 고도화 | 개발팀 | 콘서트/일정 조회 외 예약 조회 API에도 Redis 캐시 적용 검토 |
| 오토스케일링 검토 | 인프라팀 | 티켓 오픈 이벤트 시 트래픽 급증을 대비한 수평 확장(HPA) 정책 설계 |

---

## 테스트 결과 상세

### Scenario 1: Queue Spike (대기열 토큰 발급)

**부하 프로파일**: 10s→20VU, 20s→100VU, 30s 유지, 10s 종료

| 지표 | 목표 | Small (0.5 vCPU) | Medium (1 vCPU) |
|------|------|-----------------|----------------|
| 총 요청 수 | - | 2,470 건 | 2,447 건 |
| 처리량 | > 20 req/s | 34.01 /s | 34.35 /s |
| 평균 응답 시간 | - | 6.02 ms | 2.81 ms |
| P95 응답 시간 | < 500ms | **26.96 ms ✅** | **3.91 ms ✅** |
| P99 응답 시간 | < 1000ms | **35.86 ms ✅** | **4.89 ms ✅** |
| 에러율 | < 1% | **0% ✅** | **0% ✅** |
| 토큰 발급 성공 | - | 2,470 건 | 2,447 건 |

### Scenario 2: Reservation Stress (좌석 예약)

**부하 프로파일**: 20s→20VU, 30s→50VU, 1분 유지, 20s 종료

| 지표 | 목표 | Small (0.5 vCPU) | Medium (1 vCPU) |
|------|------|-----------------|----------------|
| 총 요청 수 | - | 2,508 건 | 2,464 건 |
| 평균 응답 시간 | - | 6.50 ms | 3.95 ms |
| P95 응답 시간 | < 1000ms | **21.69 ms ✅** | **7.08 ms ✅** |
| 에러율 (custom) | < 5% | **0% ✅** | **0% ✅** |
| http_req_failed | < 5% | 49% ❌ (주1) | 49% ❌ (주1) |
| 예약 성공 | - | 50 건 | 50 건 |
| 예약 충돌 (409) | - | 1,229 건 | 1,207 건 |

> **(주1)** 좌석 소진 후 409 Conflict가 k6 HTTP 실패로 집계됨. 분산락 정상 동작. 실제 에러율 0%.

### Scenario 3: Payment Load (결제)

**부하 프로파일**: 20s→20VU, 1분30초 유지, 20s 종료

| 지표 | 목표 | Small (0.5 vCPU) | Medium (1 vCPU) |
|------|------|-----------------|----------------|
| 총 요청 수 | - | 920 건 | 910 건 |
| 평균 응답 시간 | - | 8.42 ms | 5.63 ms |
| P95 응답 시간 | < 800ms | **35.37 ms ✅** | **18.77 ms ✅** |
| 에러율 (custom) | < 2% | **0% ✅** | **0% ✅** |
| http_req_failed | < 2% | 44.57% ❌ (주2) | 44.51% ❌ (주2) |
| 결제 성공 | - | 20 건 | 20 건 |
| 결제 실패 (4xx) | - | 410 건 | 405 건 |

> **(주2)** 이미 결제된 예약에 대한 재시도 차단(4xx)이 집계됨. 중복 결제 방지 로직 정상. 실제 에러율 0%.

### Scenario 4: Concert Endurance (콘서트 조회)

**부하 프로파일**: 20s→50VU, 2분 유지, 20s 종료

| 지표 | 목표 | Small (0.5 vCPU) | Medium (1 vCPU) |
|------|------|-----------------|----------------|
| 총 요청 수 | - | 2,196 건 | 2,210 건 |
| 평균 응답 시간 | - | 3.40 ms | 1.77 ms |
| P95 응답 시간 | < 300ms | **18.00 ms ✅** | **2.34 ms ✅** |
| 에러율 | < 0.1% | **0% ✅** | **0% ✅** |
| 캐시 Hit Rate | > 80% | **100% ✅** | **100% ✅** |
| 캐시 히트 수 | - | 2,196 건 | 2,210 건 |

### 스펙별 종합 비교

| 스펙 | P95 (Queue) | P95 (예약) | P95 (결제) | P95 (조회) | 에러율 |
|------|------------|-----------|-----------|-----------|-------|
| **Small** (0.5 vCPU, 512MB) | 26.96 ms | 21.69 ms | 35.37 ms | 18.00 ms | 0% |
| **Medium** (1 vCPU, 1GB) | 3.91 ms | 7.08 ms | 18.77 ms | 2.34 ms | 0% |

**권장 스펙**: **Medium (1 vCPU / 1GB)** — Small 대비 2~5배 빠른 응답 시간으로 트래픽 급증 대응력 확보.

---

**작성일**: 2026-03-01
**브랜치**: step10
