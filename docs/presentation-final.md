# 콘서트 예약 서비스 — 기술 현황 발표

> 대상: 개발팀, 기획팀, 운영팀, 경영진 등 서비스 이해관계자 전체
> 목적: 시스템 구조 · 처리 한도 · 취약점 · 장애 대응 현황 공유

---

## 목차

1. [서비스 개요 & 시스템 구조](#1-서비스-개요--시스템-구조)
2. [얼마나 많은 요청을 처리할 수 있나](#2-얼마나-많은-요청을-처리할-수-있나)
3. [어떤 취약점이 있는가](#3-어떤-취약점이-있는가)
4. [장애 발생 시 어떻게 대응하는가](#4-장애-발생-시-어떻게-대응하는가)
5. [개선 로드맵](#5-개선-로드맵)

---

## 1. 서비스 개요 & 시스템 구조

### 서비스란 무엇인가

콘서트 티켓 예약 서비스. 수천 명이 동시에 동일 좌석을 노리는 **트래픽 집중 환경**에서
**한 명에게만** 좌석을 정확히 배정하는 것이 핵심 과제입니다.

```
고객이 경험하는 흐름

  1. 대기열 입장        → 순서표(토큰) 발급
  2. 콘서트 조회        → 공연 일정 · 잔여 좌석 확인
  3. 좌석 임시 배정     → 5분간 내 좌석 확보
  4. 결제              → 포인트 차감 + 좌석 확정
  5. 만료 처리         → 5분 내 미결제 시 자동 취소
```

---

### 시스템 아키텍처

```
┌─────────────────────────────────────────────────────────────────┐
│                          Clients                                 │
│                     Web / Mobile App                            │
└─────────────────────────────┬───────────────────────────────────┘
                              │ HTTPS
┌─────────────────────────────▼───────────────────────────────────┐
│                    Load Balancer / API Gateway                   │
└──────┬──────────────────────────────────────────────────────────┘
       │ REST
┌──────▼────────────────────────────────────────────────────────┐
│                    NestJS Backend API                          │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌────────┐ ┌───────┐ │
│  │  Queue   │ │ Concert  │ │Reservation│ │Payment │ │ Point │ │
│  └────┬─────┘ └────┬─────┘ └────┬─────┘ └───┬────┘ └───┬───┘ │
│       │             │             │            │          │     │
│  ┌────▼─────────────▼─────────────▼────────────▼──────────▼──┐ │
│  │              Background Jobs (Scheduler)                  │ │
│  │   예약 만료 처리 (10s)   ·   토큰 활성화 (5s)              │ │
│  └───────────────────────────────────────────────────────────┘ │
└──────────────┬─────────────────────┬──────────────────┬────────┘
               │                     │                  │
    ┌──────────▼──────┐   ┌──────────▼──────┐  ┌───────▼──────┐
    │   MySQL (RDB)   │   │  Redis (Cache   │  │    Kafka     │
    │ 예약/결제/포인트  │   │  + 분산락)      │  │ 이벤트 버스   │
    └─────────────────┘   └─────────────────┘  └──────────────┘
```

---

### 핵심 기술 스택

| 역할 | 기술 | 사용 목적 |
|------|------|---------|
| Backend | NestJS (Node.js) | REST API, 스케줄러 |
| DB | MySQL (TypeORM) | 예약/결제/포인트 영구 저장 |
| Cache / Lock | Redis | 콘서트 조회 캐싱 + 분산락 (동시 예약 방지) |
| Message Queue | Kafka (3 Brokers) | 결제 완료 → 알림/랭킹/데이터 플랫폼 연동 |
| Container | Docker Compose | 전체 인프라 로컬/배포 환경 |

---

### 데이터 모델 (핵심 관계)

```
USER ──────── USER_POINT_BALANCE  (포인트 잔액)
 │ └───────── POINT_TX            (충전/사용 이력)
 │ └───────── QUEUE_TOKEN         (대기열 순서표)
 │ └───────── RESERVATION         (예약)
 │             └────── PAYMENT    (결제)
 │
CONCERT ───── CONCERT_SCHEDULE   (공연 일정)
               └────── SEAT      (좌석 1~50번)
                        └─── RESERVATION
```

**예약 상태 흐름**:
```
HELD (임시배정, 5분) ──결제 성공──▶ CONFIRMED (확정)
                    └──5분 경과──▶ EXPIRED   (만료)
```

---

## 2. 얼마나 많은 요청을 처리할 수 있나

> 2026-03-01 부하 테스트 결과 기반 (Docker 로컬 환경 · Small vs Medium 스펙 비교)

### 테스트 스펙 정의

| 스펙 | CPU | RAM | 포트 |
|------|-----|-----|------|
| Small | 0.5 vCPU | 512 MB | 3001 |
| **Medium (권장)** | **1.0 vCPU** | **1 GB** | **3002** |

---

### 기능별 처리 한도

#### 대기열 토큰 발급 — Spike Test

> 티켓 오픈 순간 폭발적 동시 접속을 처리하는 관문

| 지표 | 목표 | Small 결과 | Medium 결과 |
|------|------|-----------|------------|
| 처리량 | > 20 req/s | **34 req/s** | **34 req/s** |
| 평균 응답 시간 | < 300ms | 6 ms | **3 ms** |
| P95 응답 시간 | < 500ms | 27 ms ✅ | 4 ms ✅ |
| 에러율 | < 1% | **0%** ✅ | **0%** ✅ |
| 최대 동시 사용자 (VU) | — | 100명 | 100명 |

**해석**: 두 스펙 모두 100명 동시 접속에서 에러 0%. 티켓 오픈 트래픽에 안정적으로 대응.
Medium은 Small 대비 응답 시간 2배 빠름.

---

#### 좌석 예약 — Stress Test

> 동시에 같은 좌석을 노리는 경합 상황

| 지표 | 목표 | Small 결과 | Medium 결과 |
|------|------|-----------|------------|
| P95 응답 시간 | < 1,000ms | 22 ms ✅ | 7 ms ✅ |
| 에러율 (비즈니스) | < 5% | **0%** ✅ | **0%** ✅ |
| 예약 성공 수 | — | 50건 | 50건 |
| 좌석 소진 후 정상 거부 (409) | — | 1,229건 | 1,207건 |
| 최대 동시 사용자 (VU) | — | 50명 | 50명 |

**해석**: 50명이 동시에 예약을 시도해도 P95 22ms 이내. 분산락으로 중복 예약 완벽 차단.
좌석 소진 후 409 Conflict는 정상 동작 (비즈니스 에러율 0%).

---

#### 결제 처리 — Soak Test

> 지속 부하에서 메모리 누수 없이 안정적으로 처리

| 지표 | 목표 | Small 결과 | Medium 결과 |
|------|------|-----------|------------|
| P95 응답 시간 | < 800ms | 35 ms ✅ | 19 ms ✅ |
| 에러율 (비즈니스) | < 2% | **0%** ✅ | **0%** ✅ |
| 결제 성공 수 | — | 20건 | 20건 |
| 중복 결제 차단 (4xx) | — | 410건 | 405건 |

**해석**: 2분 30초 지속 부하에서도 메모리 누수 없이 안정적. 중복 결제 시도는 모두 차단.

---

#### 콘서트 조회 — Endurance Test

> Redis 캐시가 조회 트래픽 전량 처리

| 지표 | 목표 | Small 결과 | Medium 결과 |
|------|------|-----------|------------|
| P95 응답 시간 | < 300ms | 18 ms ✅ | 2 ms ✅ |
| 에러율 | < 0.1% | **0%** ✅ | **0%** ✅ |
| 캐시 Hit Rate | > 80% | **100%** ✅ | **100%** ✅ |
| 처리량 | — | 13.5 req/s | 13.4 req/s |

**해석**: 첫 요청 이후 모든 조회가 Redis에서 처리. DB 조회 부하 사실상 0.
Medium P95 2ms — 사용자는 즉각적인 응답을 경험.

---

### 처리 한도 한눈에 보기

```
기능              처리량        P95 응답   에러율   수용 동시 사용자
─────────────────────────────────────────────────────────────────
대기열 토큰 발급   34 req/s      4 ms      0%       100명 (테스트 최대)
좌석 예약          18 req/s      7 ms      0%        50명 (활성 토큰 한도)
결제 처리           6 req/s     19 ms      0%        20명 (테스트 설정)
콘서트 조회        13 req/s      2 ms      0%        50명

※ Medium 스펙 (1 vCPU / 1 GB) 기준
※ 로컬 Docker 환경 — 실 서버에서는 더 높은 수치 기대
```

---

## 3. 어떤 취약점이 있는가

### 예측된 리스크 — 구조적 한계

#### 1. 분산락 경합 → DB 커넥션 점유

```
상황: 50명이 동시에 같은 좌석 예약 시도
흐름: Redis 락 획득 대기(최대 3초) → 대기 중 DB 커넥션 점유
위험: DB 커넥션 풀(현재 기본값 10개) 고갈 → 신규 요청 타임아웃
```

| 현재 설정 | 위험도 | 실제 테스트 영향 |
|---------|--------|--------------|
| 커넥션 풀: 기본값(10개) | 🔴 높음 | 로컬 환경 avg 4ms로 미발생, 실 서버에서는 위험 |
| 분산락 Wait: 3초 | 🟡 중간 | 경합 시 커넥션 3초 점유 |

#### 2. 좌석 소진 시 대량 409 응답

```
상황: 인기 공연 티켓 오픈 후 좌석 전량 소진
흐름: 이후 요청은 모두 "이미 예약된 좌석" → 409 반환
위험: 모니터링 시스템에서 에러율 급등으로 오탐(False Alarm) 가능
      고객은 반복 시도로 피로감 경험
```

#### 3. 대기열 활성화 5초 지연

```
상황: 티켓 오픈 시 대량 대기 토큰 발급
흐름: 5초 주기 스케줄러가 WAITING → ACTIVE 전환
위험: 최대 5초 지연 + DB 부하 시 스케줄러 실행 시간 증가
```

---

### 예측 외 리스크 — 테스트 & 코드 분석으로 발견

#### B-1. Kafka 장애가 결제 실패로 직결 ⚠️

```
발견: 코드 분석
현재 동작:
  결제 완료 → Kafka 이벤트 발행 시도
  → Kafka 브로커 장애 시 → throw error
  → 결제 API 500 응답

문제:
  DB에는 결제가 저장됐는데 사용자는 실패 메시지 수신
  → 재결제 시도 → 중복 결제 가능성
```

> Kafka 인프라 장애가 핵심 비즈니스(결제)를 직접 중단시키는 구조

#### B-2. 예약 만료 이벤트 유실 → 좌석 영구 점유 ⚠️

```
발견: 코드 분석
현재 동작:
  결제 안 한 예약 → Kafka를 통해 5분 후 만료 처리
  → Consumer 재시작 또는 처리 실패 시 → 로그만 남김
  → Dead Letter Queue(DLQ) 없음 → 이벤트 유실

문제:
  만료 처리 누락 → 해당 좌석이 HELD 상태로 영구 잠김
  → 실제 구매 불가 좌석 발생
```

> 단, Reservation Scheduler(10초 주기)가 Fallback으로 동작 — 최대 10초 내 자동 복구

#### B-3. Kafka 미연결 시 이벤트 무음 유실 ⚠️

```
현재 동작:
  Kafka Producer 미연결 상태 → 이벤트 전송 건너뜀(skipping)
  → 예외 없음 → 알림, 랭킹, 데이터 플랫폼으로 이벤트 미전달

문제:
  결제는 성공했으나 → 고객 알림 미발송
                    → 랭킹 업데이트 누락
                    → 데이터 플랫폼 집계 누락
```

---

### 취약점 한눈에 보기

```
위험도   취약점                          비즈니스 영향
────────────────────────────────────────────────────────────
🔴 높음  Kafka 장애 → 결제 500          결제 불가 + 데이터 불일치
🔴 높음  예약 만료 이벤트 유실           좌석 영구 점유 (수동 복구 필요)
🔴 높음  DB 커넥션 풀 기본값            고부하 시 전체 API 타임아웃
🟡 중간  분산락 경합 → 커넥션 점유      응답 지연, 간헐적 타임아웃
🟡 중간  대기열 활성화 지연 (5초)       고객 대기 경험 저하
🟢 낮음  캐시 무효화 지연 (10분)        일정 변경 후 최대 10분 구버전 표시
```

---

## 4. 장애 발생 시 어떻게 대응하는가

### 장애 탐지 기준 (모니터링 알림)

| 알림 등급 | 조건 | 의미 |
|---------|------|------|
| 🚨 P0 긴급 | 5xx 에러율 > 1% (1분 지속) | 서비스 전체 장애 |
| 🚨 P0 긴급 | DB 커넥션 > 25개 (80%) | 커넥션 풀 고갈 임박 |
| 🚨 P0 긴급 | Redis 응답 없음 (30초) | 예약/결제 전체 불가 |
| ⚠️ P1 경고 | Kafka 전송 실패 발생 | 알림/랭킹 미발송 가능 |
| ⚠️ P1 경고 | 결제 성공률 < 95% | 결제 흐름 이상 |
| ℹ️ P2 주의 | HELD 좌석 만료 미처리 > 10건 | 좌석 잠김 가능성 |
| ℹ️ P2 주의 | 대기열 WAITING > 200명 (10분) | 활성화 지연 |

---

### 장애 유형별 즉시 대응 가이드

#### 시나리오 1: 결제 API 500 에러 급증

```
원인 후보: Kafka 장애 / DB 커넥션 고갈 / Redis 장애

Step 1. 원인 파악
  → Kafka 브로커 상태 확인: docker logs broker1 --tail 100
  → DB 커넥션 수 확인:      SHOW STATUS LIKE 'Threads_connected'
  → Redis ping 확인:        redis-cli ping

Step 2-A. Kafka 장애인 경우
  → Kafka 재시작 후 서비스 자동 복구 확인
  → 장애 구간 미발송 이벤트 수동 재발행 (알림/랭킹 보상)

Step 2-B. DB 커넥션 고갈인 경우
  → 유휴 커넥션 강제 정리
  → 필요 시 앱 재시작 (커넥션 풀 초기화)

Step 3. 영향 범위 확인
  → 결제 성공/실패 건수 집계
  → 중복 결제 여부 확인: HAVING COUNT(*) > 1 (payment 테이블)
```

---

#### 시나리오 2: 좌석이 HELD 상태로 잠겨 구매 불가

```
원인: 예약 만료 Consumer 장애 또는 이벤트 유실

Step 1. 상태 확인
  SELECT reservation_id, seat_no, held_expires_at
  FROM reservation
  WHERE status = 'HELD' AND held_expires_at < NOW();

Step 2. 즉시 복구
  UPDATE reservation
  SET status = 'EXPIRED'
  WHERE status = 'HELD' AND held_expires_at < NOW();

Step 3. 원인 조사
  → Reservation Scheduler 로그 확인
  → Kafka Consumer Lag 확인
  → 재발 방지: DLQ 적용 검토
```

---

#### 시나리오 3: 대기열에서 ACTIVE 전환이 안 됨

```
원인: Queue Scheduler 지연 또는 DB 부하

Step 1. 상태 확인
  SELECT status, COUNT(*) FROM queue_token
  WHERE created_at > NOW() - INTERVAL 10 MINUTE
  GROUP BY status;

Step 2. 즉시 복구
  → 스케줄러 실행 주기 임시 단축 (1초)
  → MAX_ACTIVE_TOKENS 핫픽스 (50 → 100) 후 배포

Step 3. DB 부하 여부 확인
  SHOW PROCESSLIST;
```

---

### 장애 대응 흐름

```
장애 감지 (모니터링 알림)
      │
      ▼
원인 파악 (Kafka / DB / Redis?)
      │
      ├── Kafka 장애 ──▶ 재시작 → 이벤트 수동 재발행
      │
      ├── DB 커넥션 ──▶ 유휴 Kill → 풀 크기 증설 배포
      │
      ├── Redis 장애 ──▶ 재시작 → 분산락 / 캐시 복구 확인
      │
      └── 좌석 잠김 ──▶ SQL UPDATE → Consumer 재시작
      │
      ▼
영향 범위 집계 (결제 성공률, 미발송 이벤트)
      │
      ▼
고객 영향 보상 (필요 시) + 재발 방지 개선 등록
```

---

## 5. 개선 로드맵

### Short-term (즉시 ~ 2주)

| 항목 | 효과 |
|------|------|
| DB 커넥션 풀 명시 설정 (`connectionLimit: 30`) | 커넥션 고갈 위험 제거 |
| k6 `http_req_failed` threshold 재정의 | 오탐 제거, 모니터링 정확도 향상 |
| 배포 스펙 Medium (1 vCPU / 1GB) 확정 | 응답 시간 2~5배 개선 |

### Mid-term (1~4주)

| 항목 | 효과 |
|------|------|
| Transactional Outbox 패턴 적용 | Kafka 장애와 결제 트랜잭션 분리 |
| 예약 만료 Consumer에 DLQ 적용 | 이벤트 유실 → 좌석 잠김 방지 |
| Prometheus + Grafana 모니터링 구축 | 장애 탐지 시간 5분 → 30초 |
| 대기열 Event-Driven 전환 (Polling 보조) | 활성화 지연 5초 → 즉시 |

### Long-term (1개월 이후)

| 항목 | 효과 |
|------|------|
| Redis Sentinel 도입 | Redis SPOF 제거 |
| 부하 테스트 CI 자동화 | 배포마다 성능 회귀 자동 검출 |
| 오토스케일링 적용 | 티켓 오픈 이벤트 트래픽 자동 대응 |

---

## 핵심 메시지 요약

```
✅ 무엇을 잘 하고 있나

  · 100명 동시 접속 → P95 4ms, 에러율 0%  (티켓 오픈 대응 가능)
  · 분산락으로 중복 예약 완벽 차단
  · Redis 캐시로 조회 트래픽 DB 부하 Zero
  · 결제 중복 방지 로직 정상 동작


⚠️ 지금 당장 개선이 필요한 것

  · DB 커넥션 풀 기본값 → 고부하 시 고갈 위험  [1순위]
  · Kafka 장애 = 결제 500 → 트랜잭션 분리 필요 [1순위]
  · 예약 만료 이벤트 유실 가능성 → DLQ 적용    [2순위]


📋 권장 배포 스펙

  Medium (1 vCPU / 1 GB) × 2대 이상
  Small 대비 2~5배 빠른 응답, 트래픽 급증 대응 여유 확보
```

---

**작성일**: 2026-03-01 | **브랜치**: step10
